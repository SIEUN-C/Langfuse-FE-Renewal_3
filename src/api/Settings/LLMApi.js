// ---â–¼ ì—ëŸ¬ë¥¼ ë” ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ì²˜ë¦¬í•˜ëŠ” í—¬í¼ í•¨ìˆ˜ â–¼---
const handleApiResponse = async (response) => {
    if (!response.ok) {
        const contentType = response.headers.get('content-type');
        // ì‘ë‹µì´ JSON í˜•ì‹ì´ë©´, JSON ì•ˆì˜ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©
        if (contentType && contentType.includes('application/json')) {
            const errorData = await response.json();
            throw new Error(errorData.message || `API Error: ${response.statusText}`);
        }
        // ì‘ë‹µì´ JSONì´ ì•„ë‹ˆë©´ (HTML ì—ëŸ¬ í˜ì´ì§€ ë“±), ìƒíƒœ ì½”ë“œë¡œ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ìƒì„±
        throw new Error(`Server returned a non-JSON error: ${response.status} ${response.statusText}`);
    }
    // DELETE ìš”ì²­ì²˜ëŸ¼ ì‘ë‹µ ë³¸ë¬¸ì´ ì—†ëŠ” ì„±ê³µ ì‚¬ë¡€ë¥¼ ìœ„í•´ í™•ì¸
    const contentType = response.headers.get('content-type');
    if (contentType && contentType.includes('application/json')) {
        return response.json();
    }
    return response; // ë³¸ë¬¸ì´ ì—†ê±°ë‚˜ JSONì´ ì•„ë‹Œ ì„±ê³µ ì‘ë‹µì€ ê·¸ëŒ€ë¡œ ë°˜í™˜
};

// GET: LLM Connection ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
export const getLlmConnections = async (page, limit, base64Credentials) => {
    const response = await fetch(`/api/public/llm-connections?page=${page}&limit=${limit}`, {
        headers: {
            'Authorization': `Basic ${base64Credentials}`
        }
    });
    if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
    }
    return handleApiResponse(response);
};

// PUT: LLM Connection ìƒì„± ë˜ëŠ” ìˆ˜ì • (Upsert)
export const saveLlmConnection = async (connectionData, base64Credentials) => {
    const response = await fetch('/api/public/llm-connections', {
        method: 'PUT',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Basic ${base64Credentials}`
        },
        body: JSON.stringify({
            provider: connectionData.provider,
            adapter: connectionData.adapter,
            secretKey: connectionData.apiKey,
            baseURL: connectionData.baseUrl || null,
            withDefaultModels: connectionData.enableDefaultModels,
            customModels: connectionData.customModels,
            extraHeaders: connectionData.extraHeaders,
        })
    });
    return handleApiResponse(response);
};

// DELETE: LLM Connection ì‚­ì œ
export const deleteLlmConnection = async (provider, base64Credentials) => {
    const encodedProvider = encodeURIComponent(provider);
    const response = await fetch(`/api/public/llm-connections/${encodedProvider}`, {
        method: 'DELETE',
        headers: {
            'Authorization': `Basic ${base64Credentials}`
        }
    });
    return handleApiResponse(response);
};

// â–¼ ì´ í•¨ìˆ˜ëŠ” 'CreateTrace.jsx'ë§Œì„ ìœ„í•´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.
// "ì „ì²´ ëª©ë¡ ë§ê³ , ê·¸ëƒ¥ ê¸°ë³¸ê°’ í•˜ë‚˜ë§Œ ì¤˜" ë¼ëŠ” ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
/**
 * Langfuseì— ì„¤ì •ëœ ì²« ë²ˆì§¸(ê¸°ë³¸) LLM Connection ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
 * @param {string} base64Credentials - ì¸ì¦ì„ ìœ„í•œ Base64 ì¸ì½”ë”©ëœ ìê²© ì¦ëª…
 * @returns {Promise<{provider: string, model: string}|null>} providerì™€ modelì´ í¬í•¨ëœ ê°ì²´ ë˜ëŠ” null
 */
export const getDefaultLlmConnection = async (base64Credentials) => {
    // ì²« í˜ì´ì§€ë§Œ ì¡°íšŒí•˜ì—¬ ì²« ë²ˆì§¸ ì—°ê²° ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    const result = await getLlmConnections(1, 1, base64Credentials);

    if (result && result.data && result.data.length > 0) {
        const connection = result.data[0];
        // í•´ë‹¹ ì—°ê²°ì— ì»¤ìŠ¤í…€ ëª¨ë¸ì´ ì •ì˜ë˜ì–´ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ 'gpt-3.5-turbo'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        const model = connection.customModels && connection.customModels.length > 0
            ? connection.customModels[0]
            : 'gpt-3.5-turbo';

        return {
            provider: connection.provider,
            model: model,
            adapter: connection.adapter, // ğŸ‘ˆ adapter ì •ë³´ ì¶”ê°€
        };
    }
    // ì„¤ì •ëœ ì—°ê²°ì´ ì—†ìœ¼ë©´ nullì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    return null;
};